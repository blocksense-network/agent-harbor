<!-- cSpell:ignore erms subtests subtest SGID -->

### Overview

This document tracks the implementation and testing status of the FUSE adapter for AgentFS, providing a cross-platform filesystem with snapshots, writable branches, and per-process branch binding. The FUSE adapter serves as the Linux host implementation, bridging the Rust AgentFS core to the Linux kernel via libfuse.

Goal: Deliver a production-ready FUSE adapter that passes comprehensive filesystem compliance tests, integrates seamlessly with the AgentFS control plane, and provides high-performance file operations through the Linux kernel interface.

<!-- cSpell:ignore memmove -->

Approach: The core FUSE adapter implementation is now complete and compiles successfully. Next steps include comprehensive integration testing with mounted filesystems, performance benchmarking, and compliance validation using automated test suites in CI environments.

**Latest run ‚Äì 2025-11-21:** Full harness rerun on branch `feat/agentfs-fuse-f7`. F1‚ÄìF5, F7, F8, F9, and F10 all passed (logs under `logs/fuse-*-20251121-*`), including `just test-pjdfstest-full` with only the expected privileged `chmod/12.t` failures. F6 performance still below targets (seq_write ~0.42√ó, seq_read ~0.28√ó, metadata ~0.11√ó, concurrent_write ~0.13√ó) in `logs/fuse-performance-20251121-113521/summary.json`.

### Milestones and tasks (with automated success criteria)

**F1. FUSE Adapter Core Implementation** ‚ö†Ô∏è CORE COMPLETE WITH KNOWN ISSUES (4‚Äì6d)

- **Deliverables**:
  - Complete FUSE adapter implementation mapping all major FUSE operations to AgentFS Core calls
  - `.agentfs/control` ioctl-based control plane for snapshots and branches
  - Cache configuration mapping from `FsConfig.cache` to `fuse_config`
  - Inode-to-path mapping for filesystem operations
  - Special handling for `.agentfs` directory and control file

- **Success criteria (unit + integration tests)**:
  - All core FUSE operations implemented and mapped to AgentFS Core
  - Control plane ioctl flows pass with SSZ union type validation
  - pjdfstests subset green with basic filesystem operations
  - Cache knobs (attr_timeout, entry_timeout, negative_timeout) properly configured
  - Full pjdfstest suite executes for every supported AgentFS backstore mode (InMemory, HostFs directory, RamDisk) with FD forwarding both disabled and enabled, with each combination matching the established baseline

- **Implementation Details**:
  - Implemented complete FUSE adapter (`AgentFsFuse`) that maps all major FUSE operations to AgentFS Core calls
  - Added `.agentfs/control` file support with ioctl-based control plane for snapshot.create, snapshot.list, branch.create, and branch.bind operations
  - Implemented full control message handling with SSZ union type validation
  - Added cache configuration mapping from `FsConfig.cache` to `fuse_config` (attr_timeout, entry_timeout, negative_timeout)
  - Implemented inode-to-path mapping for filesystem operations
  - Added special handling for `.agentfs` directory and control file
  - Implemented comprehensive FUSE operations: getattr, lookup, open, read, write, create, mkdir, unlink, rmdir, readdir, and advanced ops like xattr, utimens
  - Added conditional compilation with `fuse` feature flag to support cross-platform development
  - Implemented process PID-based branch binding for per-process filesystem views

- **Key Source Files**:
  - `crates/agentfs-fuse-host/src/main.rs` - Main binary with config loading and mount logic
  - `crates/agentfs-fuse-host/src/adapter.rs` - FUSE adapter implementation mapping operations to core
  - `crates/agentfs-fuse-host/Cargo.toml` - Dependencies and feature flags
  - `crates/agentfs-core/src/config.rs` - Added serde derives and Default implementations for FsConfig
  - `pjdfstest` - POSIX filesystem test suite runner added to Nix dev environment
  - `Justfile` - Added testing targets: `mount-fuse` for mounting, `test-fuse-basic` for smoke tests, `setup-pjdfstest-suite` for automated suite setup, `run-pjdfstest` for comprehensive testing
  - `docs/PJDFSTest-Guide.md` - Comprehensive guide for running and debugging pjdfstest suite

- **Verification Results**:
  - [x] I1 FUSE host basic ops pass - Code compiles successfully and implements all FUSE operations with correct client PID handling; requires integration testing with mounted filesystem
  - [x] I2 Control plane ioctl flows pass with SSZ union type validation - SSZ serialization implemented with proper error handling; requires testing with mounted filesystem
  - [x] pjdfstests subset green - unlink/rename/mkdir/rmdir subsets pass on the mounted `/tmp/agentfs` target (see `logs/pjdfs-subset-20251115-053905`)
  - [x] **Full pjdfstest suite executed** - Complete test run completed with 237 test files and 8789 total tests
  - [ ] **F1.1 Implement truncate/ftruncate operations** - Multiple truncate operations return `EOPNOTSUPP` (operation not supported):
    - `truncate/00.t`: 10/21 tests failed (file truncation not implemented)
    - `truncate/02.t`: 2/5 tests failed
    - `truncate/03.t`: 2/5 tests failed
    - `truncate/05.t`: 6/15 tests failed
    - `truncate/12.t`: 1/3 tests failed
    - `ftruncate/00.t`: 8/26 tests failed
    - `ftruncate/02.t`: 2/5 tests failed
    - `ftruncate/03.t`: 2/5 tests failed
    - `ftruncate/05.t`: 6/15 tests failed
  - [ ] **F1.2 Fix chown permission enforcement** ‚Äì pjdfstest now only reports the upstream `chown/00.t` TODO diagnostics (IDs 650, 654, 665‚Äì666, 671‚Äì672, etc.), but we are keeping this box open until the harness clears those TODOs or we ship a targeted override; documenting the limitation prevents us from silently regressing.
  - [ ] **F1.3 Fix chmod permission enforcement** ‚Äì `chmod/12.t` still fails because unprivileged FUSE mounts are forced `nosuid`/`nodev` by the kernel, so Linux rejects the open before AgentFS can clear the SUID/SGID bits. Fix requires a privileged mount path; we keep this unchecked and track the limitation under F5.
  - [ ] **F1.4 Fix link operation permissions** - Hard link creation permission issues:
    - `link/00.t`: 19/202 tests failed
  - [ ] **F1.5 Fix open permission enforcement** - File open permission validation failures:
    - `open/00.t`: 9/47 tests failed
    - `open/02.t`: 1/4 tests failed
    - `open/03.t`: 1/4 tests failed
    - `open/05.t`: 1/12 tests failed
    - `open/06.t`: 24/144 tests failed
  - [ ] **F1.6 Fix symlink permission enforcement** - Symlink creation permission issues:
    - `symlink/05.t`: 2/12 tests failed
    - `symlink/06.t`: 2/12 tests failed
  - [ ] **F1.7 Fix utimensat permission enforcement** - Timestamp modification permission issues:
    - `utimensat/06.t`: 1/13 tests failed
    - `utimensat/07.t`: 6/17 tests failed
    - `utimensat/08.t`: 2/9 tests failed

- **Outstanding Tasks**:
  - **Implement truncate/ftruncate system calls** in AgentFS Core and FUSE adapter
  - **Audit and fix permission checking logic** for chown, chmod, link, open, symlink, and utimensat operations
  - **Review root_bypass_permissions implementation** - may be incorrectly applied
  - **Add comprehensive permission test coverage** to prevent regression
  - **Automate pjdfstest matrix runs** across every backstore mode √ó FD-forwarding on/off combination until the verification criterion above is continuously enforced

**F2. FUSE Mount/Unmount Cycle Testing** (3‚Äì4d)

- **Deliverables**:
  - Automated mount cycle tests using block devices and loopback mounts
  - Proper cleanup and device management utilities
  - Mount failure handling and error reporting
  - Integration with CI pipeline for regular validation

- **Success criteria (automated integration tests)**:
  - Full mount cycle works: create device ‚Üí mount ‚Üí operations ‚Üí unmount ‚Üí cleanup
  - Mount failures properly detected and reported with actionable error messages
  - Multiple consecutive mount/unmount cycles work without resource leaks
  - Device cleanup works reliably even after failed mounts

- **Automated Test Plan**:
  - **T2.1 Basic Mount Cycle**: Create loopback device from file, mount FUSE filesystem, verify mount point exists, unmount, verify cleanup
  - **T2.2 Mount Failure Handling**: Test various failure scenarios (invalid device, permission denied, corrupted filesystem) and verify proper error reporting
  - **T2.3 Resource Leak Prevention**: Run multiple mount/unmount cycles and verify no file descriptors, processes, or temporary files are leaked
  - **T2.4 Concurrent Mounts**: Test multiple FUSE mounts running simultaneously without interference

- **Verification Results**:
  - [x] T2.1 Basic Mount Cycle ‚Äì `scripts/test-fuse-mount-cycle.sh` automates build ‚Üí mount ‚Üí sanity ops ‚Üí unmount with logs under `logs/fuse-mount-cycle-20251115-062328`
  - [x] T2.2 Mount Failure Handling ‚Äì `scripts/test-fuse-mount-failures.sh` covers non-directory and permission-denied mount points; latest run logged at `logs/fuse-mount-failures-20251115-065419`
  - [x] T2.3 Resource Leak Prevention ‚Äì `scripts/test-fuse-mount-cycle.sh` now enforces clean start/finish and was run with `MOUNT_CYCLE_ITERS=5` (see `logs/fuse-mount-cycle-20251115-065825`)
  - [x] T2.4 Concurrent Mounts ‚Äì `scripts/test-fuse-mount-concurrent.sh` mounts multiple instances simultaneously; latest run logged at `logs/fuse-mount-concurrent-20251115-070522`

**F3. FUSE Filesystem Operations Testing** (4‚Äì5d)

- **Deliverables**:
  - Comprehensive test suite covering all basic filesystem operations
  - File creation, reading, writing, deletion, and metadata operations
  - Directory operations (mkdir, rmdir, readdir) with proper listing
  - Symlink creation and resolution

- **Success criteria (automated integration tests)**:
  - All basic filesystem operations work through FUSE interface: create, read, write, delete, mkdir, rmdir, readdir
  - File content round-trip validation (write data, read back, compare SHA-256)
  - Directory operations preserve proper ordering and metadata
  - Symlink operations work correctly with proper attribute reporting

- **Automated Test Plan**:
  - **T3.1 File CRUD Operations**: Create files with various sizes, write content, read back and verify, delete files
  - **T3.2 Directory Operations**: Create nested directory structures, list contents, verify proper ordering and metadata
  - **T3.3 Metadata Operations**: Test chmod, chown, utimens operations through FUSE interface
  - **T3.4 Symlink Operations**: Create symlinks, resolve them, verify they appear correctly in directory listings
  - **T3.5 Large File Handling**: Test files larger than page size to ensure proper read/write chunking

- **Verification Results**:
  - [x] T3.1‚ÄìT3.5 basic operations ‚Äì `scripts/test-fuse-basic-ops.sh` automates CRUD, directory, metadata, symlink, and large-file tests; latest run logged at `logs/fuse-basic-ops-20251115-092526`

**F3.2. Negative Path and Error Code Validation** (2‚Äì3d)

- **Deliverables**:
  - Fast-running integration test suite validating correct POSIX errno codes
  - Comprehensive error condition testing before full compliance suites
  - Error propagation validation through FUSE adapter

- **Success criteria (automated integration tests)**:
  - All tests fail with the specific, correct errno as expected
  - Error codes match POSIX specifications for filesystem operations
  - No crashes or incorrect error handling in failure scenarios

- **Automated Test Plan**:
  - **T3.2.1 ENOENT Validation**: Verify open, stat, unlink, rmdir, etc., on non-existent paths fail with ENOENT
  - **T3.2.2 EEXIST Validation**: Verify mkdir or creat (without O_TRUNC) on an existing path fails with EEXIST
  - **T3.2.3 ENOTEMPTY Validation**: Verify rmdir on a non-empty directory fails with ENOTEMPTY
  - **T3.2.4 EISDIR/ENOTDIR Validation**: Verify unlink on a directory fails with EISDIR; rmdir on a file fails with ENOTDIR; mkdir using a file as part of the path fails with ENOTDIR
  - **T3.2.5 ENAMETOOLONG Validation**: Verify creating a file with a name > 255 bytes fails with ENAMETOOLONG

- **Verification Results**:
  - [x] T3.2 negative path suite ‚Äì `scripts/test-fuse-negative-ops.sh` exercises ENOENT/EEXIST/ENOTEMPTY/EISDIR/ENOTDIR/ENAMETOOLONG cases; latest run logged at `logs/fuse-negative-ops-20251115-092751`

**F3.5. Overlay Semantics Validation** (3‚Äì4d)

- **Deliverables**:
  - Automated integration test suite verifying AgentFS overlay behaviors
  - Pass-through reads, copy-up writes, and whiteout operations testing
  - Lower/upper layer interaction validation through FUSE interface

- **Success criteria (automated integration tests)**:
  - All overlay test cases pass, demonstrating correct merged upper/lower view
  - Pass-through reads work without triggering copy-up operations
  - Copy-up semantics preserve lower layer data integrity
  - Whiteout operations correctly hide lower layer entries

- **Automated Test Plan**:
  - **T3.5.1 Pass-through Read**: stat and read a large file that exists only in the lower layer; assert operation succeeds with correct content and no copy-up triggered (no new file created in upper/backstore layer)
  - **T3.5.2 Copy-up on Write**: Open and write to a file that exists only in the lower layer; assert upper entry is created in backstore, lower file remains unchanged, and subsequent reads reflect new upper content
  - **T3.5.3 Metadata-only Overlay**: chmod or setxattr on a file that exists only in the lower layer; assert upper metadata entry is created but data is not copied (for lazy copy-up mode); stat reflects new metadata while data serves from lower layer
  - **T3.5.4 Whiteout Validation**: unlink a file that exists only in the lower layer; assert file disappears from readdir in FUSE mount while original file remains untouched in lower layer
  - **T3.5.5 Merged Directory Listing**: readdir on a directory with files in both lower and upper layers (including whiteouts); assert list correctly merges both with upper-layer entries and whiteouts taking precedence
- **Verification Results**:
  - [x] Overlay harness ‚Äì `scripts/test-fuse-overlay-ops.sh` exercises pass-through reads, copy-up writes, metadata-only overlay, whiteouts, and merged listings; latest run logged at `logs/fuse-overlay-ops-20251115-100209`

**F4. FUSE Control Plane Integration Testing** (3‚Äì4d)

- **Deliverables**:
  - Automated tests for control plane operations through mounted filesystem
  - Snapshot creation, listing, and deletion via `.agentfs/control`
  - Branch creation and binding operations
  - Process isolation verification

- **Success criteria (automated integration tests)**:
  - Control plane operations functional via `.agentfs/control` file ioctl interface
  - Snapshot operations work correctly through mounted filesystem interface
  - Branch operations create proper isolated views
  - Process binding changes filesystem content visibility as expected

- **Automated Test Plan**:
  - **T4.1 Control File Access**: Verify `.agentfs/control` file exists and is accessible through FUSE mount
  - **T4.2 Snapshot Operations**: Create snapshots via control interface, verify persistence across mounts
  - **T4.3 Branch Operations**: Create branches from snapshots, verify content isolation
  - **T4.4 Process Binding**: Test per-process branch binding with multiple processes seeing different content
- **Verification Results**:
  - [x] T4.1‚ÄìT4.4 control-plane suite ‚Äì `scripts/test-fuse-control-plane.sh` now rejects bogus branch IDs, binds two independent PIDs to the same branch, confirms default-PID reads still work, and exercises snapshot-list across an unmount/remount (branch-local writes remain blocked by the current FsCore snapshot implementation, so the harness asserts read-only isolation for now). Latest log: `logs/fuse-control-plane-20251115-130217`.
  - [ ] Fix FsCore‚Äôs post-snapshot write denial so the harness can validate branch-local divergence (currently tracked in `notes/fuse_pjdfs_context.md`).

**F5. pjdfstests Compliance Suite** (4‚Äì6d)

- **Deliverables**:
  - Full pjdfstests integration with automated result parsing
  - Test result analysis and failure categorization
  - Baseline establishment for supported/unsupported operations
  - Regression detection for future changes

- **Success criteria (automated compliance tests)**:
  - pjdfstest suite runs completely against mounted FUSE filesystem
  - Critical filesystem compliance tests pass (basic operations, metadata, permissions)
  - Test results automatically parsed and categorized
  - Baseline performance established with no regressions

- **Automated Test Plan**:
  - **T5.1 pjdfstest Execution**: Run full pjdfstest suite against mounted AgentFS, capture all output
  - **T5.2 Result Analysis**: Parse test results, categorize passes/failures/skips
  - **T5.3 Critical Test Validation**: Ensure all basic POSIX filesystem operations pass
  - **T5.4 Regression Detection**: Compare results against established baseline, fail on regressions
- **Verification Results**:
  - [x] Full-suite harness ‚Äì `scripts/test-pjdfstest-full.sh` (`just test-pjdfstest-full`) sets up pjdfstest, mounts AgentFS with `--allow-other`, streams `prove -vr` output to `logs/pjdfstest-full-<ts>/pjdfstest.log`, and persists a machine-readable `summary.json`. The current baseline of known failures lives in `specs/Public/AgentFS/pjdfstest.baseline.json`; the harness compares every run against it (latest log: `logs/pjdfstest-full-20251119-072207/`).
  - [x] CI gating ‚Äì GitHub Actions now runs the pjdfstest job after the FUSE harness; it executes `SKIP_FUSE_BUILD=1 just test-pjdfstest-full`, compares results to `specs/Public/AgentFS/pjdfstest.baseline.json`, and uploads the log directory so regressions fail automatically.
  - [x] Current compliance status ‚Äì `logs/pjdfstest-full-20251119-072207/summary.json` shows a clean run except for the upstream `chown/00.t` TODO diagnostics and the kernel-expected `chmod/12.t` nosuid failure. The refreshed baseline mirrors this output so any regression outside those known exceptions fails the harness immediately.
  - [x] Regression watch ‚Äì `unlink/14.t` briefly failed (subtest 6) when the kernel returned an empty read after `unlink`; we reran `just pjdfs-file unlink/14.t` and two consecutive full-suite harnesses (`logs/pjdfstest-full-20251119-063815/` and `‚Ä¶065317/`), both green. If the kernel behaviour changes we will promote the reproduction into the baseline.
  - [ ] Kernel limitation snapshot ‚Äì `chmod/12.t` remains an expected failure even under the new privileged re-mount (`scripts/test-pjdfstest-full.sh` now unmounts the user session, remounts via `sudo` for the SUID subset, then unmounts again). Linux still denies SUID-clearing writes for FUSE before they reach AgentFS, so the privileged pass simply documents the limitation. Until we ship a truly privileged mount helper or kernel passthrough, this checkbox stays open (see `man mount.fuse(8)`).

**F6. Performance Benchmarking Suite** (3‚Äì4d) üîÑ IN PROGRESS

- **Deliverables**:
  - Automated performance benchmarks for various operation types
  - Comparison against baseline filesystems (tmpfs, ext4)
  - Memory usage and CPU utilization tracking
  - Performance regression detection
  - Linux passthrough fast path (FUSE_PASSTHROUGH) instrumentation and validation

- **Success criteria (automated performance tests)**:
  - Sequential read/write throughput measured and compared to baselines
  - Memory usage bounded and tracked across operations
  - Performance remains stable under load
  - Automatic regression detection with configurable thresholds
  - When kernel ‚â•6.9 is available, passthrough-backed sequential workloads approach ‚â•0.75√ó baseline

- **Automated Test Plan**:
  - **T6.1 Throughput Benchmarks**: Measure sequential read/write performance for various file sizes
  - **T6.2 Memory Usage Tracking**: Monitor memory consumption during intensive operations
  - **T6.3 Concurrent Access**: Test performance under multiple concurrent readers/writers
  - **T6.4 Metadata Operations**: Benchmark directory listing, attribute operations, and control plane calls
- **Verification Results**:
  - [x] Performance harness ‚Äì `scripts/test-fuse-performance.sh` (`just test-fuse-performance`) mounts AgentFS with a HostFs backstore, runs sequential read/write, metadata, and 4-way concurrent write benchmarks against a host baseline, and emits structured logs (`results.jsonl` + `summary.json`). Latest release-mode run (after the async writeback pipeline): `logs/fuse-performance-20251117-070644/summary.json` ‚Äì still failing the ‚â•‚ÄØ0.75√ó ratios (seq_write ‚âà‚ÄØ0.33√ó, seq_read ‚âà‚ÄØ0.32√ó, metadata ‚âà‚ÄØ0.24√ó, concurrent_write ‚âà‚ÄØ0.22√ó).
  - [x] Perf profiling ‚Äì Captured cold-cache sequential-write profiling runs (4√ó16‚ÄØGiB writes each) under `logs/perf-profiles/agentfs-perf-profile-20251116-125536-run1/`, `‚Ä¶125630-run2/`, and `‚Ä¶125721-run3/` using `perf record -g -F 400 -p <fuse_pid>`; all show the worker-channel bottleneck (crossbeam backoff + memmove).
  - [x] Release-mode perf profiling ‚Äì Repeated the sequential-write captures using the **release** FUSE host binary; logs live under `logs/perf-profiles/agentfs-perf-profile-20251116-130943-release-run1/`, `‚Ä¶131032-release-run2/`, `‚Ä¶131121-release-run3/`, plus the latest async-writeback captures (`logs/perf-profiles/agentfs-perf-20251117-064244/` and `‚Ä¶064348/`) which show the kernel stuck in page-cache allocation (`pagecache_get_page ‚Üí __alloc_pages ‚Üí clear_page_erms`).
  - [x] Regression thresholds ‚Äì The perf harness now enforces default minimum ratios (seq_write/read ‚â•‚ÄØ0.75, metadata ‚â•‚ÄØ0.5, concurrent_write ‚â•‚ÄØ0.5) via `MIN*_RATIO` env vars and fails if any run drops below the configured floor.
  - [ ] Passthrough validation ‚Äì AgentFsFuse can request `FUSE_PASSTHROUGH` (Linux ‚â•6.9) behind `AGENTFS_FUSE_PASSTHROUGH=1`. Need HostFs backstore + kernel support to confirm handles switch to passthrough (metrics logged via `agentfs::fuse`) and to re-run the F6 harness for updated ratios.

**F7. Stress Testing and Fault Injection** (4‚Äì5d)

- **Deliverables**:
  - Automated stress testing with concurrent operations
  - Fault injection for error path testing using mock storage/backstore layer
  - Resource exhaustion testing (file descriptors, memory)
  - Crash recovery validation with data integrity checks

- **Success criteria (automated stress tests)**:
  - Stress tests complete without filesystem corruption or crashes
  - Fault injection does not violate core invariants
  - Resource exhaustion handled gracefully
  - Data integrity maintained under adverse conditions

- **Automated Test Plan**:
  - **T7.1 Concurrent Operations**: Multiple processes performing intensive file operations simultaneously
  - **T7.2 Fault Injection**: Introduce a mock storage/backstore layer in agentfs-core that can be configured via the control plane to return EIO or ENOSPC for specific operations, and verify the FUSE adapter propagates these errors correctly
  - **T7.3 Resource Exhaustion**: Test with maximum file descriptors, memory pressure, and large file counts
  - **T7.4 Crash Recovery**: Run a workload (e.g., file creation loop). kill -9 the agentfs-fuse-host process. Restart the host and run a checker to ensure the filesystem mounts cleanly and invariants are intact (understanding that in-memory data may be lost, but the state isn't corrupted)

- **Verification Results**:
  - [x] Automated stress harness ‚Äì `scripts/test-fuse-stress.sh` (`just test-fuse-stress`) now drives the full F7 suite. It mounts AgentFS with a HostFs backstore, raises `RLIMIT_NOFILE` to 65‚ÄØ536, runs the `agentfs-fuse-stress` concurrency workload, toggles resource limits for fd-exhaustion, and executes the crash-recovery watchdog. Each run emits structured artifacts under `logs/fuse-stress-<ts>/` (`results.jsonl`, `summary.json`, per-phase logs). Latest full run: `logs/fuse-stress-20251119-151555/summary.json`.
  - [x] Concurrency coverage ‚Äì `agentfs-fuse-stress run` records per-operation stats, benign/fatal error rates, and tree fingerprints so regressions surface automatically. The default workload (`threads=16`, `duration=120s`, `max_files=4096`) completes without fatal errors and produced ~217‚ÄØk mixed operations in the latest run.
  - [x] Resource exhaustion ‚Äì The harness temporarily reduces `RLIMIT_NOFILE` for the resource phase, drives the `fd_exhaust` scenario until the kernel returns `EMFILE`, and captures peak `/proc/self/fd` counts, cleanup latency, and errno so descriptor leaks are visible. `logs/fuse-stress-20251119-151555/resource/report.json` shows the run passing with 3‚ÄØ963 opened handles and an `EMFILE` termination as expected.
  - [x] Crash recovery ‚Äì The crash phase now logs a deterministic workload, fingerprints it, `kill -9`s the fuse host, remounts AgentFS, and verifies the filesystem can be re-mounted cleanly (digest mismatches are noted but tolerated because AgentFS currently rebuilds state in-memory). Results land in `crash/pre-crash.json` + shell logs, and the harness fails only if remount/fingerprint steps break.

**F8. Extended Attributes and Special Features** (3‚Äì4d)

- **Deliverables**:
  - Extended attributes (xattrs) support testing
  - Special file types and permissions via mknod
  - FUSE-specific mount options and features
  - Advanced I/O operations validation

- **Success criteria (automated feature tests)**:
  - Extended attributes round-trip correctly
  - Special file types created and handled properly
  - FUSE mount options work as expected
  - Advanced I/O features integrate correctly with AgentFS core

- **Automated Test Plan**:
  - **T8.1 Extended Attributes**: Test xattr get/set/list operations through FUSE interface
  - **T8.2 mknod Testing**: Test creation of special files including FIFOs (mknod my_fifo p) and verify they appear correctly in stat and readdir
  - **T8.3 Mount Option Testing**: Verify key FUSE mount options including allow_other, default_permissions, and custom cache TTLs (attr_timeout, entry_timeout, negative_timeout) from F1 are correctly passed to FsCore
  - **T8.4 Advanced I/O Testing**: Test optional core features like fallocate (for both preallocation and punching holes) and copy_file_range (if implemented)

- **Verification Results**:
  - [x] Extended attribute harness (`scripts/test-fuse-xattrs.sh`, `just test-fuse-xattrs`) covers user/trusted namespaces with set/list/remove flows. Latest run: `logs/fuse-xattrs-20251119-171957/summary.json`.
  - [x] Special node harness (`scripts/test-fuse-mknod.sh`, `just test-fuse-mknod`) validates FIFO creation and stat metadata. Latest run: `logs/fuse-mknod-20251119-172003/summary.json`.
  - [x] Mount option harness (`scripts/test-fuse-mount-options.sh`, `just test-fuse-mount-options`) exercises `allow_other`, kernel `default_permissions`, and cache TTL propagation. Latest run: `logs/fuse-mount-options-20251119-172010/summary.json`.
  - [x] Advanced I/O harness (`scripts/test-fuse-advanced-io.sh`, `just test-fuse-advanced-io`) verifies posix_fallocate, punch-hole fallocate, and copy_file_range semantics. On this kernel `copy_file_range` returns `EINVAL/EBADF`, so the harness records a fallback manual copy while logging the kernel limitation. Latest run: `logs/fuse-advanced-io-20251119-171929/summary.json`.

**F9. Cross-Version Compatibility Testing** (2‚Äì3d)

- **Deliverables**:
  - Compatibility testing across different libfuse versions
  - Kernel version compatibility validation
  - Distribution-specific testing (Ubuntu, Fedora, etc.)
  - Backward compatibility assurance

- **Success criteria (automated compatibility tests)**:
  - Works with libfuse 2.x and 3.x
  - Compatible with multiple kernel versions
  - Functions correctly across different Linux distributions
  - No regressions in older environments

- **Automated Test Plan**:
  - **T9.1 libfuse Version Compatibility**: Test against libfuse 2.x and 3.x APIs
  - **T9.2 Kernel Version Testing**: Validate with different kernel versions in CI matrix
  - **T9.3 Distribution Testing**: Test on multiple Linux distributions (Ubuntu, Fedora, CentOS)
  - **T9.4 API Compatibility**: Ensure backward compatibility with older FUSE APIs

- **Verification Results**:
  - [x] Compatibility harness ‚Äì `scripts/test-fuse-compat.sh` (`just test-fuse-compat`) mounts/unmounts AgentFS with both `fusermount` (libfuse 2.x helper) and `fusermount3` (libfuse 3.x helper) and records helper/kernel versions plus JSON summary. Latest run on NixOS 6.12: `logs/fuse-compat-20251121-143907/summary.json` (both helpers succeeded).
  - [ ] Broader matrix ‚Äì Multi-distro/kernel coverage remains to be exercised; current CI step runs on the privileged NixOS runner and validates helper compatibility only.

**F10. Security and Robustness Testing** (3‚Äì4d)

- **Deliverables**:
  - Security-focused tests for privilege escalation prevention
  - Input validation including path traversal attack testing
  - Comprehensive permission model validation
  - Sandbox boundary testing

- **Success criteria (automated security tests)**:
  - No privilege escalation vulnerabilities in control plane operations
  - Malformed inputs handled gracefully without crashes
  - Proper permission checking enforced for all operations including root bypass and sticky bit semantics
  - Sandbox boundaries maintained across all operations

- **Automated Test Plan**:
  - **T10.1 Privilege Escalation**: Test that unprivileged users cannot escalate privileges through FUSE operations
  - **T10.2 Input Validation**: Test handling of malformed paths, invalid ioctl requests, and corrupted data; specifically test path traversal attacks using paths like ../../etc/passwd from within the mount to ensure proper containment
  - **T10.3 Permission Checking**: Expand into detailed matrix based on AgentFS permissions: test standard owner/group/other rwx permissions; test root_bypass_permissions (both enabled and disabled); test sticky bit (0o1000) on directories (only owner or dir-owner can unlink files); test permission checks for chmod/chown (e.g., only owner/root can chmod)
  - **T10.4 Sandbox Testing**: Ensure FUSE adapter cannot access resources outside its designated boundaries

- **Verification Results**:
  - [x] F10 plan captured in `notes/fuse_f10_plan.md` based on the F8 template, covering privilege attempts, input validation, sandboxing, and robustness.
  - [x] Permission matrix harness added (`scripts/test-fuse-security-permissions.sh`, `just test-fuse-security-permissions`) and wired into CI. Latest run: `logs/fuse-security-permissions-20251120-053931/summary.json`.
  - [x] Privilege escalation harness added (`scripts/test-fuse-security-privileges.sh`, `just test-fuse-security-privileges`) covering nobody/root flows across sticky dirs and mode toggles. Latest run: `logs/fuse-security-privileges-20251120-053944/summary.json`.
  - [x] Input validation harness added (`scripts/test-fuse-security-input.sh`, `just test-fuse-security-input`) covering traversal, overlong names, invalid UTF-8, and special character handling. Latest run: `logs/fuse-security-input-20251120-053953/summary.json`.
  - [x] Sandbox harness added (`scripts/test-fuse-security-sandbox.sh`, `just test-fuse-security-sandbox`) to block symlink escapes and traversal; latest run: `logs/fuse-security-sandbox-20251120-054314/summary.json`.
  - [x] Robustness harness added (`scripts/test-fuse-security-robustness.sh`, `just test-fuse-security-robustness`) driving fd exhaustion and file-size caps; latest run: `logs/fuse-security-robustness-20251120-054421/summary.json`.

**F11. Packaging and Distribution** (2‚Äì3d)

- **Deliverables**:
  - Automated build and packaging scripts
  - Distribution packages for major Linux distributions
  - Installation and setup documentation
  - Integration with system package managers

- **Success criteria (automated packaging tests)**:
  - Reproducible build artifacts generated automatically
  - Distribution packages install and work correctly
  - Setup documentation validated through automated testing
  - Package integrity and signatures verified

- **Automated Test Plan**:
  - **T11.1 Build Reproducibility**: Verify builds produce identical artifacts across environments
  - **T11.2 Package Installation**: Test package installation and basic functionality on target distributions
  - **T11.3 Documentation Validation**: Automated testing of setup procedures and documentation
  - **T11.4 Package Integrity**: Verify package signatures, dependencies, and file permissions

**F12. AH FS Snapshots Daemon FUSE Mount Management (Linux)** (4‚Äì5d)

- **Deliverables**:
  - Enhance `crates/ah-fs-snapshots-daemon` so the daemon can spawn and monitor the `agentfs-fuse-host` binary (from `crates/agentfs-fuse-host`).
  - Add lifecycle RPCs (SSZ `Request` variants) for `MountAgentfsFuse` with the correct mount flags/backstore configuration, `UnmountAgentfsFuse`, and `StatusAgentfsFuse`, persisting mountpoints, PID files, and log paths under `/run/agentfs-fuse/`.
  - Surface explicit backstore parameters (InMemory, HostFs directory, RamDisk) in the RPCs so downstream tests can request the same combinations described in `AgentFS.md` and `AgentFS-Core.md`; ensure mount logs report which backstore is active.
  - Emit structured logs (mount command, PID, stderr tail, reason for restart) via `tracing` so `just check-ah-fs-snapshots-daemon` can report actionable diagnostics when the mount fails.
  - Ship a `ah-fs-snapshots-daemonctl` CLI plus updated `just start/stop/check` helpers so engineers can drive mount/unmount/status RPCs without bespoke scripts.

- **Implementation details**:
  - The daemon now owns a long-lived `DaemonState`/`AgentfsFuseManager` pair that supervises the `agentfs-fuse-host` child, rewrites config files in `/run/agentfs-fuse/`, and restarts crashed hosts with exponential backoff while persisting PID/log/status metadata for troubleshooting.
  - New SSZ union variants (`MountAgentfsFuse`, `UnmountAgentfsFuse`, `StatusAgentfsFuse`) plus strongly typed backstore payloads keep RPCs in sync with `FsConfig`; helper binaries and tests validate InMemory, HostFs, and RamDisk modes.
  - `ah-fs-snapshots-daemonctl fuse {mount,unmount,status}` wraps the RPCs, exposes JSON for CI, and powers `scripts/check-ah-fs-snapshots-daemon.sh` and the new crash harness (`scripts/test-fs-daemon-mount.sh`). `just start-ah-fs-snapshots-daemon` now launches only the daemon, while `just stop-‚Ä¶` relies on the supervisor‚Äôs shutdown unmount path.

- **Success criteria (automated integration tests)**:
  - `just start-ah-fs-snapshots-daemon` launches the daemon and leaves mount orchestration to RPC callers (e.g., `ah-fs-snapshots-daemonctl fuse mount`). `just stop-‚Ä¶` now only shuts down the daemon, relying on the supervisor‚Äôs shutdown path to handle unmount/cleanup.
  - The daemon survives `agentfs-fuse-host` crashes by restarting the mount (respecting exponential backoff) and exposes mount health over the existing Unix socket so callers can block until the filesystem is ready.
  - Integration tests in `crates/ah-fs-snapshots-daemon/tests` cover mount/unmount flows, status queries, and failure propagation (bad config, missing fuse device) without requiring manual sudo steps beyond launching the daemon.

- **Automated Test Plan**:
  - **T12.1 Mount RPC Test**: Tokio integration test that sends `MountAgentfsFuse` over the daemon socket, waits for `/tmp/agentfs/.agentfs/control`, and then issues `UnmountAgentfsFuse`.
  - **T12.2 Crash/Restart Harness**: Script under `scripts/test-fs-daemon-mount.sh` that kills the `agentfs-fuse-host` PID mid-run and asserts the daemon restarts it while preserving the mountpoint.
  - **T12.3 Status CLI**: Extend `scripts/check-ah-fs-snapshots-daemon.sh` to call the new status RPC and verify output (mount path, pid, health) so CI can gate on daemon readiness.

- **Verification Results**:
  - [x] T12.1 Mount RPC Test ‚Äì `cargo test -p ah-fs-snapshots-daemon fuse_manager::mount_and_unmount_stub_host` boots the daemon-managed supervisor against a stub `agentfs-fuse-host`, drives the Mount/Status/Unmount RPCs over the Unix socket, and asserts the runtime metadata files under `/run/agentfs-fuse/` are populated.
  - [x] T12.2 Crash/Restart Harness ‚Äì `scripts/test-fs-daemon-mount.sh` kills the live `agentfs-fuse-host` PID via the new status RPC, waits for the daemon‚Äôs exponential-backoff restart, and fails with log excerpts when the PID never changes.
  - [x] T12.3 Status CLI ‚Äì `scripts/check-ah-fs-snapshots-daemon.sh` shells out to `ah-fs-snapshots-daemonctl fuse status --json`, verifies the reported `state=running`/PID/log path, and fails fast (with hints) when the daemon isn‚Äôt healthy.

**F13. AgentFS Daemon Orchestration for macOS Interpose Mounts** - COMPLETE

- **Deliverables**:
  - Reuse the same `ah-fs-snapshots-daemon` control plane to optionally launch `crates/agentfs-daemon` on macOS (driven by a new `mount_agentfs_interpose` RPC) so the CLI/harness can request process-isolated mounts without re-implementing shim plumbing.
  - Bridge the daemon‚Äôs configuration to the Swift/FSKit host by generating per-request socket paths/runtime directories compatible with `agentfs_interpose_e2e_tests`, copying the behavior currently hard-coded in `tests/fs-snapshots-test-harness/src/bin/driver.rs`.
  - Provide per-platform policy: Linux requests `agentfs-fuse-host`, macOS requests `agentfs-daemon`; both share the same SSZ API surface so higher layers don‚Äôt need #cfg soup while enabling macOS callers to request unique sockets for every workspace/matrix shard.
  - Document the new macOS path in `specs/Public/AgentFS/FUSE.status.md` and `specs/Public/AgentFS/AgentFS.status.md`, explaining how interpose + daemon-managed mounts relate to the FUSE/Linux flow and how the CLI drives the new hints.

- **Implementation details**:
  - Added an `AgentfsInterposeManager` supervisor plus new SSZ request/response types, allowing the daemon to spawn and monitor `agentfs-daemon` via the shared control plane with restart/backoff semantics and JSON status persistence under `/tmp/agentfs-interpose`.
  - Introduced optional interpose hint payloads (socket path + runtime dir) so each daemon RPC can request its own control socket/log sandbox; callers transparently fall back to the legacy behavior when talking to older daemons.
  - `ah-fs-snapshots-daemonctl` now exposes `interpose {mount,unmount,status}` with `--socket-path/--runtime-dir` flags; the status printer mirrors the FUSE JSON schema so `scripts/check-ah-fs-snapshots-daemon.sh` can auto-detect whether it is running on Linux (FUSE) or macOS (interpose) before gating CI.
  - `AgentFsHarness::start` switched from spawning `agentfs-daemon` directly to calling the new RPC, consuming the returned socket path and wiring the shim env vars + reconnect hook so the FS snapshots harness no longer shells out to bespoke scripts. The provider also forwards `AGENTFS_INTERPOSE_SOCKET`/`AGENTFS_INTERPOSE_RUNTIME_DIR` env overrides as hints so every matrix shard gets an isolated socket.
  - `specs/Public/AgentFS/FUSE.status.md`, `specs/Public/AgentFS/AgentFS.status.md`, and the AgentFS harness runbook now describe the unified workflow, and macOS interpose sockets are surfaced through `DaemonClient` APIs used by the provider and CLI.

- **Success criteria (automated integration tests)**:
  - `just start-ah-fs-snapshots-daemon` on macOS spawns `agentfs-daemon`. Tests confirm clients can bind to the daemon over the exported Unix socket thought the interpose shim mechanism.
  - macOS status checks report the active branch/mount list, so support engineers can tell whether the daemon is serving interpose clients without digging through launchctl logs.

- **Automated Test Plan**:
  - **T13.1 Interpose RPC Test**: macOS-only integration test in `crates/ah-fs-snapshots-daemon/tests` that issues `mount_agentfs_interpose`, verifies the returned socket path accepts connections, then unmounts.
  - **T13.2 Harness Regression**: Update `tests/fs-snapshots-test-harness/tests/smoke.rs` to run once with daemon-managed interpose and assert the same readiness logs appear as before.

- **Verification Results**:
  - [x] T13.1 Interpose RPC Test ‚Äì `cargo test -p ah-fs-snapshots-daemon interpose_manager::tests::mount_and_unmount_stub_daemon` now boots the daemon via the new RPC, waits for the reported socket, kills the stub `agentfs-daemon`, and confirms the supervisor tears it down cleanly.
  - [x] T13.1b Interpose Hint Test ‚Äì `cargo test -p ah-fs-snapshots-daemon interpose_manager::tests::mount_respects_socket_hint` proves the supervisor honours per-request socket/runtime overrides and persists the metadata for status consumers.
  - [x] T13.2 Harness Regression ‚Äì `cargo test -p ah-fs-snapshots --lib --features agentfs` exercises the updated `AgentFsHarness::start` path, proving the provider prepares workspaces using the daemon-managed interpose mount with the same readiness logs consumed by `tests/fs-snapshots-test-harness`.

**F14. AgentFS FUSE Provider Validation in FS Snapshots Harness** (3‚Äì4d) - COMPLETE

- **Deliverables**:
  - Extend `tests/fs-snapshots-test-harness/src/bin/driver.rs` so Linux runs can select the AgentFS provider by exporting `AGENTFS_TRANSPORT=fuse` (today this simply discriminates against the future `AGENTFS_TRANSPORT=interpose` mode we plan to support on Linux via `LD_PRELOAD`), discovering the already-running daemon/mount (same pattern used by existing FS snapshot tests), and passing the resolved mount/root into the scenarios module.
  - Add Linux-targeted copies of `crates/ah-fs-snapshots/tests/agentfs_provider.rs` and `provider_core_behavior_agentfs.rs` (guarded by `#[cfg(all(feature = "agentfs", target_os = "linux"))]`) that connect to the FUSE mount, assert `.agentfs/control` presence, and drive the same prepare ‚Üí snapshot ‚Üí branch ‚Üí cleanup assertions already enforced on macOS.
  - Update `tests/fs-snapshots-test-harness/src/scenarios.rs` so the AgentFS branch of `provider_matrix` delegates to the FUSE-backed provider on Linux while retaining the interpose shim flow on macOS; record daemon/mount diagnostics in the harness logs for CI triage.
  - Parameterize the FS snapshots suite to run against multiple AgentFS backstores (InMemory, HostFs directory, RamDisk) so every provider test exercises the Kernel-Backstore Proxy behaviors documented in `specs/Public/AgentFS/AgentFS.md` (¬ßBackstore) and `AgentFS-Core.md` (¬ßBackstore Manager). Each run must tag logs with `backstore=<mode>` for triage.
  - Remove the legacy `AH_ENABLE_AGENTFS_PROVIDER` opt-in on Linux so the provider is always available when the FUSE mount can be detected; expose helpful skip messages only when prerequisites (daemon, fuse device) are missing.
  - Provide reusable Rust helpers to probe the daemon socket/mount status (mirroring the current FS snapshot policy where tests assume the daemon was started out-of-band via `just start-ah-fs-snapshots-daemon`); fail fast with actionable skips when the daemon is unavailable instead of trying to launch it.

- **Implementation Details**:
  - `tests/fs-snapshots-test-harness/src/agentfs.rs` provides `FuseHarness` with `new()`, `socket_path()`, `mount_point()`, `repo_root()`, `ensure_mounted()`, and `prepare_repo()` methods.
  - Transport selection (`AGENTFS_TRANSPORT=fuse` vs `interpose`) is implemented via `requested_transport()` with platform-specific defaults (Linux‚ÜíFUSE, macOS‚Üíinterpose).
  - `BackstoreSpec` enum supports `InMemory`, `HostFs`, and `RamDisk` modes; `parse_backstore_matrix()` parses `AGENTFS_BACKSTORE_MATRIX` environment variable.
  - Linux opt-in removed: `experimental_flag_enabled()` in `crates/ah-fs-snapshots/src/agentfs.rs` returns `true` unconditionally on Linux.
  - `agentfs_provider_matrix_linux()` in `scenarios.rs` drives the provider matrix test for AgentFS on Linux FUSE.
  - Linux tests in `agentfs_provider.rs` (`agentfs_prepare_snapshot_and_cleanup_cycle_fuse`) and `provider_core_behavior_agentfs.rs` exercise the FUSE-backed provider with graceful skips when prerequisites are missing.

- **Success criteria (automated integration tests)**:
  - `cargo test --package ah-fs-snapshots --features agentfs -- --nocapture integration` passes on a Linux FUSE host without requiring any opt-in environment variables, assuming the daemon is already running (tests should emit clear skips when it is not).
  - `tests/fs-snapshots-test-harness -- provider-matrix --provider agentfs` succeeds on Linux for every supported backstore mode (InMemory, HostFs directory, RamDisk), producing the same workspace/snapshot metrics as macOS and leaving no stale readonly exports or cleanup tokens.
  - CI artifacts (from `just test-fs-snapshots`) include the daemon log, mount table snapshot, and harness stdout whenever the AgentFS provider fails, with log metadata indicating which backstore mode was under test.

- **Automated Test Plan**:
  - **T14.1 Harness Readiness Check**: Rust integration test under `tests/fs-snapshots-test-harness/tests` that pings the daemon socket/mount (without launching it), mirroring the existing FS snapshot tests‚Äô ‚Äúassume running‚Äù policy and skipping when unavailable.
  - **T14.2 AgentFsProvider (FUSE) Smoke**: Linux-only unit test that mirrors `agentfs_provider.rs`, verifying `SnapshotProviderKind::AgentFs` resolves to the FUSE backend, `.agentfs/control` responds to ioctl pings, and cleanup tokens remove the workspace.
  - **T14.3 Provider Matrix (FUSE)**: Harness scenario that runs `fs-snapshots-harness-driver provider-matrix --provider agentfs` with `AGENTFS_TRANSPORT=fuse`, collecting `logs/fs-snapshots-agentfs-<ts>.log` and comparing timings to macOS baselines (the same entry point will later mode-switch to `AGENTFS_TRANSPORT=interpose` when Linux LD_PRELOAD support ships).
  - **T14.4 Backstore Sweep**: Wrapper test (Rust or shell) that iterates over the supported backstore modes (InMemory, HostFs directory, RamDisk) by issuing the appropriate daemon RPCs, running the full FS snapshots suite for each, and asserting that all modes pass or produce mode-specific diagnostics.

- **Verification Results**:
  - [x] T14.1 Harness Lifecycle Hook ‚Äì harness smoke test now probes the daemon socket/mount and skips cleanly when the daemon isn‚Äôt running
  - [x] T14.2 AgentFsProvider (FUSE) Smoke ‚Äì Linux-specific test added to reuse the daemon-backed provider and assert ioctl readiness when FUSE is available
  - [x] T14.3 Provider Matrix (FUSE) ‚Äì driver + scenarios can run the provider matrix via `AGENTFS_TRANSPORT=fuse`, discovering the mount through the daemon helpers
  - [x] T14.4 Backstore Sweep ‚Äì harness iterates over InMemory, HostFs, and RamDisk backstores, tagging logs with the active mode and skipping gracefully when prerequisites are missing

**F15. AgentFS Control Plane Wiring for `ah agent fs snapshot`** (3‚Äì4d) - COMPLETE

- **Deliverables**:
  - Reuse the existing `agentfs-control-cli` (`crates/agentfs-control-cli`) logic to implement ioctl + SSZ request/response handling inside the `ah agent fs snapshot` command, so snapshot create/list/branch/bind requests can target the mounted FUSE filesystem through `.agentfs/control`.
  - Add configuration discovery so `ah agent fs snapshot` can locate the mount started by `just start-fs-snapshots-daemon` (default `/tmp/agentfs`), overridable via CLI flags/env vars that also feed upcoming `ah agent sandbox` / `ah agent start` flows.
  - Ensure the command records structured logs (snapshot IDs, branch IDs, errno on failure) and integrates with the existing `agentfs-control.request.logical.json` SSZ schema validation.
  - Provide documentation/examples showing how to replace `cargo run -p agentfs-control-cli` with the user-facing `ah agent fs snapshot` flows while keeping the low-level CLI available for debugging.

- **Implementation Status**:
  The CLI structure has been implemented in `crates/ah-cli/src/agent/fs.rs` with the following commands:

  **Fully Implemented:**
  - `ah agent fs status [--path PATH] [--json] [--verbose] [--detect-only]` ‚Äì Runs filesystem detection and reports provider capabilities; uses the `provider_for()` detection machinery.
  - `ah agent fs snapshot [--recorder-socket PATH]` ‚Äì Creates a snapshot using the detected provider's `snapshot_now()` method. Works with all providers (ZFS, Btrfs, AgentFS, Git).
  - `ah agent fs interpose get --mount PATH` ‚Äì Retrieves interpose configuration via ioctl SSZ requests to `.agentfs/control`.
  - `ah agent fs interpose set --mount PATH [--enabled BOOL] [--max-copy-bytes N] [--require-reflink BOOL]` ‚Äì Sets interpose configuration via ioctl SSZ requests.
  - `ah agent fs snapshots [SESSION_ID] [--mount PATH] [--json]` ‚Äì Lists snapshots from the AgentFS control plane via ioctl SSZ requests. Outputs in human-readable or JSON format.
  - `ah agent fs branch create <SNAPSHOT_ID> [--name NAME] [--mount PATH]` ‚Äì Creates a branch from a snapshot via ioctl SSZ requests.
  - `ah agent fs branch bind <BRANCH_ID> [--pid PID] [--mount PATH]` ‚Äì Binds a process (default: current) to a branch via ioctl SSZ requests.
  - `ah agent fs branch exec <BRANCH_ID> [--mount PATH] -- <CMD>` ‚Äì Binds to a branch and executes a command in that context.

  **Stub Implementations (TODO):**
  - `ah agent fs init-session` ‚Äì Prints placeholder message; no actual session initialization. Requires database persistence integration.

  **Implementation Details:**
  - All ioctl-based commands share the transport layer from `crates/ah-cli/src/transport.rs` which provides `ControlTransport`, `build_*_request()` helpers, and `send_control_request()`.
  - Mount point discovery defaults to `/tmp/agentfs` and can be overridden via `--mount` flag on all relevant commands.
  - Error handling surfaces actionable messages (control file missing, ioctl errno) and exits non-zero when the daemon is unavailable.
  - The `branch exec` command binds the current process to the specified branch before spawning the child command, enabling child processes to inherit the branch view.
  - **Privilege Dropping**: The `ah-fs-snapshots-daemon` now spawns `agentfs-fuse-host` as the requesting user (via `setuid`/`setgid` in `pre_exec`), ensuring the FUSE mount and control file are owned by the user. This eliminates the need for `--allow-other` to access the control file.
  - **Control File Ownership**: The FUSE adapter now uses the process UID/GID for the `.agentfs/control` file and `.agentfs` directory attributes instead of hardcoding root ownership.

- **Key Source Files**:
  - `crates/ah-cli/src/agent/fs.rs` ‚Äì Main CLI implementation for `ah agent fs` commands
  - `crates/ah-cli/src/transport.rs` ‚Äì Control plane transport layer with ioctl SSZ request/response handling
  - `crates/ah-cli/tests/cli_request_builders_test.rs` ‚Äì SSZ schema validation tests (T15.3)
  - `crates/agentfs-control-cli/src/main.rs` ‚Äì Reference CLI implementation for parity testing
  - `crates/ah-fs-snapshots-daemon/src/fuse_manager.rs` ‚Äì Daemon FUSE mount management with privilege dropping
  - `crates/agentfs-fuse-host/src/adapter.rs` ‚Äì FUSE adapter with process-based control file ownership
  - `scripts/test-agentfs-cli-control-plane.sh` ‚Äì CLI parity test harness (T15.1)
  - `scripts/test-agentfs-cli-failure-injection.sh` ‚Äì Failure injection test harness (T15.2)

- **Success criteria (automated integration tests)**:
  - `ah agent fs snapshot create --name smoke --mount /tmp/agentfs` successfully issues ioctl requests against the FUSE control file and prints the new snapshot ID, matching the behavior of `agentfs-control-cli snapshot-create`.
  - Control-plane parity tests prove that `snapshot list`, `branch create`, and `branch bind` produce byte-identical SSZ payloads compared to the reference CLI, guaranteeing compatibility with the daemon.
  - Error handling surfaces actionable messages (control file missing, ioctl errno) and exits non-zero when the daemon is not running.

- **Automated Test Plan**:
  - **T15.1 CLI Parity Harness**: New Rust integration test (or shell script under `scripts/test-agentfs-cli-control-plane.sh`) that starts the daemon, runs both `agentfs-control-cli` and `ah agent fs snapshot` for create/list/bind, and diff-checks their stdout/JSON outputs.
  - **T15.2 Failure Injection**: Add a harness subtest that intentionally stops the daemon mid-run to ensure `ah agent fs snapshot` reports ioctl failures with errno context and cleans up temporary files.
  - **T15.3 Schema Validation**: Extend SSZ golden tests to cover the command's request builders so deviations from `agentfs-control.request.logical.json` fail CI immediately.

- **Verification Results**:
  - [x] T15.0 CLI Structure ‚Äì `ah agent fs` subcommand structure fully implemented with status/snapshot/interpose/snapshots/branch commands; only init-session remains a stub
  - [x] T15.1 CLI Parity Harness ‚Äì `scripts/test-agentfs-cli-control-plane.sh` (`just test-agentfs-cli-parity`) validates that `ah agent fs` commands produce output compatible with `agentfs-control-cli` for snapshot list, branch create, and branch bind operations. The daemon spawns the FUSE host as the requesting user, so the control file is owned by the user and no `--allow-other` or sudo is required.
  - [x] T15.2 Failure Injection ‚Äì `scripts/test-agentfs-cli-failure-injection.sh` (`just test-agentfs-cli-failure-injection`) validates error handling when the daemon stops mid-run or is unavailable. Tests include: control file not found, I/O error after daemon kill, errno context in error messages, invalid mount path handling, and branch/interpose operations with dead daemon. All tests verify proper error reporting with actionable messages and non-zero exit codes.
  - [x] T15.3 Schema Validation ‚Äì `crates/ah-cli/tests/cli_request_builders_test.rs` (`just test-agentfs-cli-schema`) validates that CLI request builders produce SSZ-encoded requests compatible with `agentfs-control.request.logical.json`. Tests cover all control plane requests (snapshot create/list, branch create/bind, interpose get/set) with roundtrip SSZ encoding verification, schema validation, edge cases (Unicode, long names, special characters), and binary format stability. All 22 tests pass.

**F15.5. Overlay Materialization Modes Implementation** (5‚Äì6d) ‚úÖ CORE COMPLETE

This milestone implements the overlay materialization policies described in [AgentFS.md ¬ßOverlay Materialization Modes](AgentFS.md#overlay-materialization-modes) and [AgentFS-Core.md](AgentFS-Core.md). It must be completed before F16 and F17, which depend on the `--overlay-materialization` CLI flag.

**Status**: Core implementation complete with 11/13 tests passing. Remaining: T15.5.11 (large directory perf benchmarking) and T15.5.12 (macOS integration test).

- **Prerequisites**: F1‚ÄìF5 complete (basic FUSE adapter working with overlay mode).

- **Deliverables**:

  **Core Implementation (`crates/agentfs-core`):**
  - Add `MaterializationMode` enum to `config.rs` with variants `Lazy`, `Eager`, and `CloneEager`. Note: this is distinct from the existing `CopyUpMode` which controls per-file copy-up timing during operations; `MaterializationMode` controls whether the entire lower layer is materialized at branch creation time.
  - Add `materialization: MaterializationMode` and `require_clone_support: bool` to `OverlayConfig`.
  - Implement branch creation materialization logic in `vfs.rs`:
    - **Lazy**: No change to current behavior‚Äîfiles remain in lower layer until first write.
    - **Eager**: On `branch_create_from_snapshot` or `branch_create_from_current`, recursively copy all files from lower layer into the new branch's upper layer before returning. Files already in upper (from parent snapshot) are cloned via existing CoW logic.
    - **CloneEager**: Same as Eager but use filesystem-native reflink/clonefile operations (`copy_file_range` with `FICLONE`, `clonefile()` on macOS, `FSCTL_DUPLICATE_EXTENTS_TO_FILE` on Windows) instead of full data copy. Fall back to Eager if reflink fails and `require_clone_support` is false.
  - Add platform detection helpers (`can_reflink(path)`) to probe whether the backstore filesystem supports reflink.
  - Expose `MaterializationMode` through the control-plane SSZ schema so daemon clients can specify the mode when creating branches.

  **FUSE Host (`crates/agentfs-fuse-host`):**
  - Add `--overlay-materialization <lazy|eager|clone-eager>` CLI flag to `main.rs`.
  - Wire the flag through to `FsConfig.overlay.materialization` passed to `FsCore::new`.
  - Add structured log messages when materialization runs (file count, elapsed time, reflink vs copy fallback).

  **Daemon Integration (`crates/ah-fs-snapshots-daemon`):**
  - Extend the `MountAgentfsFuse` RPC to accept an optional `materialization_mode` field.
  - Forward the mode to the FUSE host process via CLI flag or config file.

- **Success criteria (automated tests)**:
  - Branch creation with `Lazy` mode completes in O(1) time regardless of lower layer file count.
  - Branch creation with `Eager` mode copies all lower layer files into the upper layer; verify via backstore inspection.
  - Branch creation with `CloneEager` mode uses reflink when available (detect via `statx` reflink flag or inode comparison); falls back to Eager when reflink unavailable.
  - Files created in lower layer AFTER branch creation with `Eager`/`CloneEager` are NOT visible in the branch.
  - Modifications to lower layer files AFTER branch creation with `Eager`/`CloneEager` do NOT affect branch contents.
  - The `require_clone_support=true` + no-reflink-filesystem combination fails branch creation with actionable error.

- **Automated Test Plan**:
  - **T15.5.1 `test_materialization_lazy_branch_creation_time`**:
    - **Properties verified**: Lazy mode branch creation is O(1)
    - **Steps**: (1) Create lower layer with 10,000 files, (2) create branch with `materialization=Lazy`, (3) verify creation time < 100ms, (4) verify backstore has 0 files (no eager copy)
    - **Platforms**: Linux (FUSE)

  - **T15.5.2 `test_materialization_eager_copies_all_files`**:
    - **Properties verified**: Eager mode copies all lower layer files to upper at branch creation
    - **Steps**: (1) Create lower layer with 100 files, (2) create branch with `materialization=Eager`, (3) inspect backstore directory, (4) verify all 100 files present in upper layer
    - **Platforms**: Linux (FUSE)

  - **T15.5.3 `test_materialization_eager_isolation_from_lower_creates`**:
    - **Properties verified**: Files created in lower layer after Eager branch creation are NOT visible
    - **Steps**: (1) Create lower layer, (2) create branch with `materialization=Eager`, (3) create new file in lower layer, (4) verify file NOT visible in branch
    - **Spec reference**: [AgentFS.md ¬ßOverlay Materialization Modes](AgentFS.md)

  - **T15.5.4 `test_materialization_eager_isolation_from_lower_modifications`**:
    - **Properties verified**: Modifications to lower layer files after Eager branch creation do NOT affect branch
    - **Steps**: (1) Create lower layer with file "test.txt" containing "original", (2) create branch with `materialization=Eager`, (3) modify lower layer file to "modified", (4) verify branch still sees "original"
    - **Spec reference**: [AgentFS.md ¬ßOverlay Materialization Modes](AgentFS.md)

  - **T15.5.5 `test_materialization_clone_eager_uses_reflink`** (Linux with Btrfs/XFS only):
    - **Properties verified**: CloneEager mode uses filesystem reflink, not full copy
    - **Steps**: (1) Create lower layer on Btrfs/XFS with 10 large files (100MB each), (2) create branch with `materialization=CloneEager`, (3) verify backstore size is < 10MB (shared blocks), (4) verify files are accessible and have correct content
    - **Platforms**: Linux with Btrfs or XFS backstore

  - **T15.5.6 `test_materialization_clone_eager_fallback_to_eager`**:
    - **Properties verified**: CloneEager falls back to Eager on filesystems without reflink (e.g., ext4, tmpfs)
    - **Steps**: (1) Create lower layer on ext4/tmpfs, (2) create branch with `materialization=CloneEager`, (3) verify branch creation succeeds, (4) verify files are copied (not reflinked), (5) verify structured log indicates fallback
    - **Platforms**: Linux with ext4/tmpfs backstore

  - **T15.5.7 `test_materialization_clone_eager_require_clone_fails`**:
    - **Properties verified**: Branch creation fails when `require_clone_support=true` and reflink unavailable
    - **Steps**: (1) Create lower layer on ext4/tmpfs, (2) attempt branch creation with `materialization=CloneEager` and `require_clone_support=true`, (3) verify creation fails with actionable error message
    - **Platforms**: Linux with ext4/tmpfs backstore

  - **T15.5.8 `test_materialization_fuse_host_cli_flag`**:
    - **Properties verified**: FUSE host accepts `--overlay-materialization` flag
    - **Steps**: (1) Start FUSE host with `--overlay-materialization eager`, (2) create branch via control plane, (3) verify branch uses Eager materialization (inspect backstore)
    - **Platforms**: Linux (FUSE)

  - **T15.5.9 `test_materialization_daemon_rpc_parameter`**:
    - **Properties verified**: Daemon RPC accepts materialization mode
    - **Steps**: (1) Send `MountAgentfsFuse` RPC with `materialization_mode=Eager`, (2) create branch, (3) verify branch uses Eager materialization
    - **Platforms**: Linux (FUSE)

  - **T15.5.10 `test_materialization_lazy_lower_visibility`**:
    - **Properties verified**: Lazy mode allows lower layer changes to be visible (documenting expected behavior)
    - **Steps**: (1) Create lower layer, (2) create branch with `materialization=Lazy`, (3) create new file in lower layer, (4) verify file IS visible in branch (expected lazy behavior)
    - **Spec reference**: [AgentFS.md ¬ßOverlay Materialization Modes](AgentFS.md)

  - **T15.5.11 `test_materialization_eager_large_directory_performance`**:
    - **Properties verified**: Eager mode handles large directories without timeout
    - **Steps**: (1) Create lower layer with 50,000 small files, (2) create branch with `materialization=Eager`, (3) verify creation completes within 60s, (4) verify all files accessible in branch
    - **Platforms**: Linux (FUSE)

  - **T15.5.12 `test_materialization_clone_eager_macos_clonefile`** (macOS only):
    - **Properties verified**: CloneEager mode uses APFS clonefile() on macOS
    - **Steps**: (1) Create lower layer on APFS with large files, (2) create branch with `materialization=CloneEager`, (3) verify files share blocks (inspect via `stat` or disk usage), (4) verify copy-on-write works for subsequent modifications
    - **Platforms**: macOS (interpose)

  - **T15.5.13 `test_materialization_mode_persisted_in_branch_metadata`**:
    - **Properties verified**: Branch metadata records which materialization mode was used
    - **Steps**: (1) Create branch with `materialization=Eager`, (2) query branch info via control plane, (3) verify response includes materialization mode field
    - **Platforms**: Linux (FUSE), macOS (interpose)

- **Implementation Details**:
  - **Core Implementation (`crates/agentfs-core/src/config.rs`):**
    - Added `MaterializationMode` enum with `Lazy` (default), `Eager`, and `CloneEager` variants with comprehensive documentation.
    - Extended `OverlayConfig` with `materialization: MaterializationMode` and `require_clone_support: bool` fields.
    - Both fields have `#[serde(default)]` for backward compatibility with existing configurations.
  - **Branch Creation Logic (`crates/agentfs-core/src/vfs.rs`):**
    - Implemented `apply_materialization()` method that dispatches to mode-specific handlers based on configuration.
    - `populate_vfs_from_lower()` creates VFS nodes for all lower layer files during Eager/CloneEager materialization, providing ZFS-like point-in-time isolation.
    - `create_file_from_lower()` reads file content from lower layer, stores in VFS storage, and creates a file node with proper metadata.
    - `materialize_directory_recursive()` handles nested directory structures with proper symlink support for backstore persistence.
    - `materialize_file()` copies individual files with metadata preservation to backstore.
    - `can_reflink(path)` probes filesystem reflink support via temporary file test (FICLONE ioctl on Linux, clonefile() on macOS).
    - `try_reflink()` provides platform-specific reflink implementation.
    - Both `branch_create_from_snapshot` and `branch_create_from_current` now call `apply_materialization()` and record materialization mode in branch metadata.
    - Added `sealed_from_lower` flag to `Branch` struct - when true (Eager/CloneEager), prevents lower layer fallback in lookup/readdir operations.
    - Added `is_branch_sealed_for_pid()` and `should_fallback_to_lower()` helper methods to check branch isolation semantics.
    - Modified `getattr_with_node_id()`, `open()`, and `readdir_plus()` to respect `sealed_from_lower` flag.
    - Added `materialization_mode` and `sealed_from_lower` fields to internal `Branch` struct and public `BranchInfo` struct for metadata queries.
  - **Backstore Methods (`crates/agentfs-core/src/storage.rs`, `crates/agentfs-core/src/types.rs`):**
    - Extended `Backstore` trait with `create_dir()`, `create_symlink()`, `write_file()`, and `set_mode()` methods for materialization support.
    - `InMemoryBackstore` returns `Unsupported` for these operations (materialization requires physical storage).
    - `HostFsBackstore` implements full filesystem operations with proper error handling.
  - **FUSE Host (`crates/agentfs-fuse-host/src/main.rs`):**
    - Added `--overlay-materialization <lazy|eager|clone-eager>` CLI argument with comprehensive help text.
    - `parse_materialization_mode()` function parses CLI strings with user-friendly error messages.
    - Materialization mode logged at startup and wired through to `FsConfig.overlay.materialization`.
  - **Daemon Integration (`crates/ah-fs-snapshots-daemon/src/types.rs`):**
    - Added `AgentfsMaterializationMode` SSZ union enum with `Lazy`, `Eager`, and `CloneEager` variants.
    - Extended `AgentfsFuseMountRequest` with `materialization_mode` field.
    - Added `to_cli_arg()` method for conversion to FUSE host CLI argument.
  - **Daemon RPC Handling (`crates/ah-fs-snapshots-daemon/src/fuse_manager.rs`):**
    - `spawn_fuse_host_command()` now passes `--overlay-materialization <mode>` argument from RPC request.
  - **CLI Tool (`crates/ah-fs-snapshots-daemon/src/bin/ah-fs-snapshots-daemonctl.rs`):**
    - Added `--materialization <lazy|eager|clone-eager>` argument to `fuse mount` subcommand.
    - `MaterializationModeKind` enum with ValueEnum derive for clap integration.
    - `as_proto()` method converts to SSZ type for RPC transport.
  - **Test Harness (`tests/fs-snapshots-test-harness/src/agentfs.rs`):**
    - Updated `AgentfsFuseMountRequest` construction to include `materialization_mode` (defaults to Lazy).
  - **Key Source Files:**
    - `crates/agentfs-core/src/config.rs` ‚Äì MaterializationMode enum, OverlayConfig fields
    - `crates/agentfs-core/src/vfs.rs` ‚Äì apply_materialization(), populate_vfs_from_lower(), can_reflink(), try_reflink(), sealed_from_lower semantics
    - `crates/agentfs-core/src/storage.rs` ‚Äì Backstore materialization method implementations
    - `crates/agentfs-core/src/types.rs` ‚Äì Backstore trait extension, BranchInfo materialization_mode and sealed_from_lower fields
    - `crates/agentfs-core/src/test_materialization.rs` ‚Äì Comprehensive materialization mode test suite (13 tests)
    - `crates/agentfs-fuse-host/src/main.rs` ‚Äì --overlay-materialization CLI flag
    - `crates/ah-fs-snapshots-daemon/src/types.rs` ‚Äì AgentfsMaterializationMode SSZ type
    - `crates/ah-fs-snapshots-daemon/src/fuse_manager.rs` ‚Äì CLI argument passthrough
    - `crates/ah-fs-snapshots-daemon/src/bin/ah-fs-snapshots-daemonctl.rs` ‚Äì CLI --materialization flag

- **Verification Results**:
  - [x] T15.5.1 Lazy Branch Creation Time ‚Äì `test_materialization_lazy_branch_creation_time` passes; Lazy mode is O(1) by design (no materialization, no VFS population)
  - [x] T15.5.2 Eager Copies All Files ‚Äì `test_materialization_eager_copies_all_files` passes; `populate_vfs_from_lower()` creates VFS nodes for all lower layer files
  - [x] T15.5.3 Eager Isolation from Lower Creates ‚Äì `test_materialization_eager_isolation_from_lower_creates` passes; `sealed_from_lower` flag prevents lower layer fallback
  - [x] T15.5.4 Eager Isolation from Lower Modifications ‚Äì `test_materialization_eager_isolation_from_lower_modifications` passes; content read from VFS not lower layer
  - [x] T15.5.5 CloneEager Uses Reflink ‚Äì `try_reflink()` with FICLONE ioctl (Linux) / clonefile (macOS) implemented; `can_reflink()` probes FS support
  - [x] T15.5.6 CloneEager Fallback to Eager ‚Äì `test_materialization_clone_eager_fallback_to_eager` passes; fallback logic when reflink unavailable
  - [x] T15.5.7 CloneEager Require Clone Fails ‚Äì `test_materialization_clone_eager_require_clone_fails` passes; returns `FsError::Unsupported` when required but unavailable
  - [x] T15.5.8 FUSE Host CLI Flag ‚Äì `--overlay-materialization` flag implemented and wired through to `FsConfig.overlay.materialization`
  - [x] T15.5.9 Daemon RPC Parameter ‚Äì `materialization_mode` field in `AgentfsFuseMountRequest` implemented and forwarded to FUSE host
  - [x] T15.5.10 Lazy Lower Visibility ‚Äì `test_materialization_lazy_lower_visibility` passes; Lazy mode uses overlay fallback (unsealed)
  - [ ] T15.5.11 Eager Large Directory Performance ‚Äì pending performance benchmarking (50k files)
  - [ ] T15.5.12 CloneEager macOS Clonefile ‚Äì implemented but awaiting macOS integration test
  - [x] T15.5.13 Mode Persisted in Branch Metadata ‚Äì `test_materialization_mode_persisted_in_branch_metadata` passes; `BranchInfo.materialization_mode` and `sealed_from_lower` fields populated

**F16. `ah agent sandbox` Integration with AgentFS** (4‚Äì5d) ‚ö†Ô∏è HARNESS COMPLETE

- **Prerequisites**: The AgentFS daemon must be running before executing these tests. Start it with `just start-ah-fs-snapshots-daemon` (requires sudo privileges). See [AgentFS Harness Runbook](../../../docs/AgentFS-Harness-Runbook.md) and [legacy/ruby/test/AGENTS.md](../../../legacy/ruby/test/AGENTS.md) for daemon startup documentation.

- **Deliverables**:
  - Update the `ah agent sandbox` CLI runtime selection logic (see `specs/Public/CLI.md`) so when `--fs-snapshots agentfs` (or the auto detector chooses AgentFS) the command discovers the already-running daemon, reuses its mount, and manages per-process branches through the control plane. In dev environments the daemon is started via `just start-ah-fs-snapshots-daemon`; in production environments, the daemon is installed as a system service and its socket is managed through the [configuration system](../Configuration.md)).
  - Wire branch binding so every sandboxed process and its child processes are assigned to its own branch by calling the control plane before launching the workload; track bindings for cleanup on exit.
  - Add user-facing logging/telemetry describing when the CLI switches between AgentFS interpose (macOS) and FUSE (Linux) backends, and expose troubleshooting hints (mount status, control file path, daemon logs).
  - Implement the high-level sandbox properties defined in [Agent-Harbor-Sandboxing-Strategies.md](../Sandboxing/Agent-Harbor-Sandboxing-Strategies.md) and [Local-Sandboxing-on-Linux.md](../Sandboxing/Local-Sandboxing-on-Linux.md) when using the AgentFS provider.

- **Implementation Details**:
  - **CLI Integration**: The `ah agent sandbox --fs-snapshots agentfs` command uses the existing `prepare_workspace_with_fallback()` function in `crates/ah-cli/src/sandbox.rs` which discovers the daemon mount, creates a snapshot, creates a branch, and binds the current process PID to the branch via the control plane ioctl interface.
  - **Branch Binding**: The `AgentFsProvider::prepare_fuse_workspace()` (Linux FUSE) and `prepare_agentfs_workspace()` (macOS interpose) methods call `branch_create()` and `branch_bind()` on the control client, ensuring every sandboxed process gets its own isolated branch view.
  - **Telemetry**: Enhanced structured logging added with `target: "ah::sandbox::agentfs"` covering provider selection, capability detection, transport type (FUSE vs interpose), mount paths, branch IDs, and troubleshooting hints when errors occur.
  - **Cleanup**: The `cleanup_prepared_workspace()` function is called in both success and error paths (including crash and interrupt) to release the branch binding and cleanup tokens.
  - **Test Harness**: Comprehensive test script `scripts/test-agentfs-sandbox.sh` (`just test-agentfs-sandbox`) covers 17 test scenarios including filesystem isolation, branch binding, cleanup, and child process handling.

- **Key Source Files**:
  - `crates/ah-cli/src/sandbox.rs` ‚Äì CLI sandbox command with AgentFS integration and enhanced telemetry
  - `crates/ah-fs-snapshots/src/agentfs.rs` ‚Äì AgentFS provider with `prepare_fuse_workspace()` and branch binding
  - `scripts/test-agentfs-sandbox.sh` ‚Äì F16 test harness covering T16.1‚ÄìT16.24
  - `Justfile` ‚Äì Added `test-agentfs-sandbox` and `test-agentfs-sandbox-all` targets

- **Success criteria (automated integration tests)**:
  - New end-to-end tests run `ah agent sandbox --fs-snapshots agentfs -- <cmd>` and verify the CLI snapshot list contains entries created through the control plane while the daemon logs show per-process branch binding.
  - Mount lifecycle automation guarantees no stale mounts remain after the CLI terminates, even when the sandboxed process crashes or the user interrupts the command.
  - All high-level sandbox properties (filesystem isolation, process isolation, network isolation, resource governance) are verified through dedicated test scenarios.

- **Automated Test Plan**:

  All tests assume the daemon is running via `just start-ah-fs-snapshots-daemon`. Tests should skip gracefully with actionable messages when the daemon is unavailable.
  - **T16.1 `test_sandbox_agentfs_basic_execution`** (`scripts/test-agentfs-sandbox.sh`):
    - **Properties verified**: Basic command execution inside sandbox with AgentFS FUSE provider
    - **Steps**: Run `ah agent sandbox --fs-snapshots agentfs -- echo "sandbox test"`, verify exit code 0 and expected output
    - **Platforms**: Linux (FUSE), macOS (interpose)

  - **T16.2 `test_sandbox_agentfs_filesystem_isolation`**:
    - **Properties verified**: Per-task workspace isolated from real working tree (snapshot + CoW); no writes outside the workspace
    - **Steps**: (1) Capture directory contents before sandbox execution, (2) run `ah agent sandbox --fs-snapshots agentfs -- bash -c "touch /tmp/marker && echo 'test' > newfile.txt"`, (3) verify host directory contents are identical before/after, (4) verify marker file does NOT exist on host
    - **Spec reference**: [Agent-Harbor-Sandboxing-Strategies.md ¬ß3 File-system semantics](../Sandboxing/Agent-Harbor-Sandboxing-Strategies.md)

  - **T16.3 `test_sandbox_agentfs_overlay_persistence`**:
    - **Properties verified**: Files written in AgentFS branch persist across sandbox invocations using the same branch
    - **Steps**: (1) Create a branch via control plane, (2) run sandbox bound to that branch and create a file, (3) run a second sandbox bound to the same branch and verify file exists
    - **Spec reference**: [AgentFS.md ¬ßPer-process branch binding](AgentFS.md)

  - **T16.4 `test_sandbox_agentfs_branch_binding`**:
    - **Properties verified**: Every sandboxed process is assigned to its own branch; control-plane logs show binding
    - **Steps**: Run sandbox, parse daemon/control-plane logs for branch binding messages, verify branch ID is recorded

  - **T16.5 `test_sandbox_agentfs_process_isolation`** (Linux only):
    - **Properties verified**: Process isolation so tools see only session processes; host PIDs invisible/inaccessible
    - **Steps**: Run `ah agent sandbox --fs-snapshots agentfs -- ps aux` inside sandbox, verify host processes are NOT visible; run `ah agent sandbox -- kill -0 1` and verify it fails (cannot signal host PID 1)
    - **Spec reference**: [Local-Sandboxing-on-Linux.md ¬ß4 Isolation requirements](../Sandboxing/Local-Sandboxing-on-Linux.md)

  - **T16.6 `test_sandbox_agentfs_network_isolation`** (Linux only):
    - **Properties verified**: Isolated networking to avoid port clashes; same-port binds possible without conflict; egress off by default
    - **Steps**: (1) Start a listener on port 8080 on host, (2) run sandbox and attempt to bind port 8080 inside, verify success (no conflict), (3) verify `curl` to external URL fails (egress blocked by default)
    - **Spec reference**: [Local-Sandboxing-on-Linux.md ¬ß7 Networking requirements](../Sandboxing/Local-Sandboxing-on-Linux.md)

  - **T16.7 `test_sandbox_agentfs_network_egress_enabled`** (Linux only):
    - **Properties verified**: Opt-in egress works when `--allow-network yes` is specified
    - **Steps**: Run `ah agent sandbox --fs-snapshots agentfs --allow-network yes -- curl -s https://example.com`, verify success

  - **T16.8 `test_sandbox_agentfs_secrets_protection`**:
    - **Properties verified**: Sensitive areas shielded by default (e.g., `~/.ssh`, `~/.gnupg`)
    - **Steps**: Run sandbox and attempt to read `~/.ssh/id_rsa` (if exists), verify access is denied or path is hidden
    - **Spec reference**: [Agent-Harbor-Sandboxing-Strategies.md ¬ß3 File-system semantics](../Sandboxing/Agent-Harbor-Sandboxing-Strategies.md)

  - **T16.9 `test_sandbox_agentfs_writable_carveouts`**:
    - **Properties verified**: Writable working copy and writable package manager caches work correctly
    - **Steps**: Run sandbox with `--mount-rw /tmp/test-cache`, verify writes to that path succeed while writes to `/etc` fail
    - **Spec reference**: [Local-Sandboxing-on-Linux.md ¬ß5.1 Baseline](../Sandboxing/Local-Sandboxing-on-Linux.md)

  - **T16.10 `test_sandbox_agentfs_cleanup_on_exit`**:
    - **Properties verified**: Deterministic teardown that removes mounts, processes, and limits; no stale mounts after CLI terminates
    - **Steps**: Run sandbox, capture mount table and cgroup list, verify cleanup after sandbox exits

  - **T16.11 `test_sandbox_agentfs_crash_cleanup`**:
    - **Properties verified**: Cleanup works even when the sandboxed process crashes or is killed
    - **Steps**: Run `ah agent sandbox --fs-snapshots agentfs -- sleep 60` in background, send SIGKILL after 2s, verify branch unbinding and mount cleanup
    - **Spec reference**: [Agent-Harbor-Sandboxing-Strategies.md ¬ß9 Platform integrations](../Sandboxing/Agent-Harbor-Sandboxing-Strategies.md)

  - **T16.12 `test_sandbox_agentfs_interrupt_cleanup`**:
    - **Properties verified**: Cleanup works when user sends SIGINT (Ctrl+C)
    - **Steps**: Run sandbox in background, send SIGINT, verify graceful cleanup

  - **T16.13 `test_sandbox_agentfs_resource_limits`** (Linux only):
    - **Properties verified**: CPU/memory/pids limits enforced on per-session basis
    - **Steps**: Run sandbox with cgroup limits, spawn fork bomb inside, verify it is contained
    - **Spec reference**: [Local-Sandboxing-on-Linux.md ¬ß11 Resource governance](../Sandboxing/Local-Sandboxing-on-Linux.md)

  - **T16.14 `test_sandbox_agentfs_debugging_enabled`** (Linux only):
    - **Properties verified**: Debugging supported within the sandbox only
    - **Steps**: Run sandbox with a child process, attempt `ptrace` attach from within sandbox (should succeed), attempt `ptrace` attach to supervisor from within sandbox (should fail)
    - **Spec reference**: [Local-Sandboxing-on-Linux.md ¬ß6 Process & debugging](../Sandboxing/Local-Sandboxing-on-Linux.md)

  - **T16.15 `test_sandbox_agentfs_readonly_baseline`**:
    - **Properties verified**: Read-only baseline of the host/system image
    - **Steps**: Run sandbox and attempt to write to `/usr/bin/`, `/etc/`, `/lib/`, verify all fail with EROFS or EPERM
    - **Spec reference**: [Local-Sandboxing-on-Linux.md ¬ß5.1 Baseline](../Sandboxing/Local-Sandboxing-on-Linux.md)

  - **T16.16 `test_sandbox_agentfs_provider_telemetry`**:
    - **Properties verified**: Structured logs report provider selection (AgentFS), mount path, and troubleshooting hints
    - **Steps**: Run sandbox with `RUST_LOG=debug`, parse logs for expected telemetry fields

  - **T16.17 `test_sandbox_agentfs_child_process_fork`**:
    - **Properties verified**: Child processes spawned via fork() inherit branch binding and filesystem isolation
    - **Steps**: Run sandbox with `bash -c 'echo before > /tmp/test.txt && (echo child > /tmp/child.txt) && cat /tmp/child.txt'`, verify both files exist in branch but not on host
    - **Spec reference**: [AgentFS.md ¬ßPer-process branch binding](AgentFS.md)

  - **T16.18 `test_sandbox_agentfs_child_process_exec`**:
    - **Properties verified**: Processes launched via exec() maintain branch binding
    - **Steps**: Run sandbox with `bash -c 'exec cat /etc/hostname'`, verify output comes from branch view (not host)

  - **T16.19 `test_sandbox_agentfs_child_process_system`**:
    - **Properties verified**: Subprocesses via system() or popen() maintain isolation
    - **Steps**: Run sandbox with a C/Python program that calls system("touch /tmp/marker"), verify marker in branch, not on host

  - **T16.20 `test_sandbox_agentfs_child_process_nohup`**:
    - **Properties verified**: Backgrounded/nohup processes maintain branch binding
    - **Steps**: Run sandbox with `bash -c 'nohup touch /tmp/bg.txt &>/dev/null & sleep 0.5'`, verify file exists in branch

  - **T16.21 `test_sandbox_agentfs_child_process_setsid`**:
    - **Properties verified**: Processes that create new sessions maintain branch binding
    - **Steps**: Run sandbox with `setsid touch /tmp/setsid.txt`, verify file in branch not on host

  - **T16.22 `test_sandbox_agentfs_child_process_double_fork`**:
    - **Properties verified**: Double-fork daemon pattern maintains branch binding
    - **Steps**: Run sandbox with script that double-forks (classic daemonization), verify daemon's writes are in branch

  - **T16.23 `test_sandbox_agentfs_child_process_shell_pipeline`**:
    - **Properties verified**: Shell pipelines with multiple processes maintain branch binding
    - **Steps**: Run sandbox with `bash -c 'echo test | tee /tmp/pipe1.txt | cat > /tmp/pipe2.txt'`, verify both files in branch

  - **T16.24 `test_sandbox_agentfs_child_process_subshell`**:
    - **Properties verified**: Subshells maintain branch binding
    - **Steps**: Run sandbox with `bash -c '(touch /tmp/sub.txt); [ -f /tmp/sub.txt ] && echo ok'`, verify "ok" output and file in branch

  - **T16.25 `test_sandbox_agentfs_base_layer_concurrent_create`**:
    - **Properties verified**: Files created in base layer after branch creation are NOT visible in sandbox (with Eager mode)
    - **Steps**: (1) Start sandbox with `--overlay-materialization eager`, (2) externally create `/tmp/base_new.txt` on host, (3) verify file is NOT visible inside sandbox
    - **Spec reference**: [AgentFS.md ¬ßOverlay Materialization Modes](AgentFS.md)

  - **T16.26 `test_sandbox_agentfs_base_layer_concurrent_modify`**:
    - **Properties verified**: Modifications to base layer files after branch creation are NOT visible in sandbox (with Eager mode)
    - **Steps**: (1) Create `/tmp/base_test.txt` with content "original", (2) start sandbox with `--overlay-materialization eager`, (3) externally modify file to "modified", (4) verify sandbox still sees "original"
    - **Spec reference**: [AgentFS.md ¬ßOverlay Materialization Modes](AgentFS.md)

  - **T16.27 `test_sandbox_agentfs_base_layer_lazy_visibility`**:
    - **Properties verified**: In Lazy mode (designed for controlled environments), unaccessed base layer modifications MAY be visible‚Äîthis is expected behavior in stable base layer environments
    - **Steps**: (1) Start sandbox with `--overlay-materialization lazy`, (2) externally create `/tmp/lazy_new.txt`, (3) verify file IS visible inside sandbox (expected in lazy mode)
    - **Spec reference**: [AgentFS.md ¬ßOverlay Materialization Modes](AgentFS.md)

  - **T16.28 `test_sandbox_agentfs_base_layer_delete_isolation`**:
    - **Properties verified**: Files deleted from base layer after branch creation remain visible in sandbox (with Eager mode)
    - **Steps**: (1) Create `/tmp/will_delete.txt`, (2) start sandbox with `--overlay-materialization eager`, (3) externally delete file, (4) verify file is STILL visible inside sandbox
    - **Spec reference**: [AgentFS.md ¬ßOverlay Materialization Modes](AgentFS.md)

  - **T16.29 `test_sandbox_agentfs_child_process_thread_spawn`**:
    - **Properties verified**: Threads spawned within sandbox inherit branch binding
    - **Steps**: Run sandbox with multi-threaded program that writes from different threads, verify all writes land in branch

  - **T16.30 `test_sandbox_agentfs_child_process_cloexec`**:
    - **Properties verified**: FD_CLOEXEC handles are properly cleaned up and child processes get fresh branch-bound FDs
    - **Steps**: Run sandbox with program that sets CLOEXEC then execs, verify exec'd process can still access branch files

- **Verification Results** (Nov 2025):
  - [x] T16.0 Test Harness ‚Äì `scripts/test-agentfs-sandbox.sh` (`just test-agentfs-sandbox`) implemented covering T16.1‚ÄìT16.24; outputs structured logs to `logs/agentfs-sandbox-<timestamp>/` with JSON summary
  - [x] T16.0.1 Enhanced Telemetry ‚Äì structured logging added to `sandbox.rs` with `target: "ah::sandbox::agentfs"` covering provider selection, capability detection, transport type, and troubleshooting hints
  - [x] T16.1 Basic Execution ‚Äì **PASSED** ‚Äì sandbox command executes successfully with AgentFS provider
  - [x] T16.2 Filesystem Isolation ‚Äì **PASSED** ‚Äì tmpfs mounted on `/tmp` for isolation; when working under AgentFS mount, AgentFS provides isolation instead
  - [~] T16.3 Overlay Persistence ‚Äì **SKIPPED** ‚Äì each sandbox creates new branch; persistence requires explicit branch reuse
  - [x] T16.4 Branch Binding ‚Äì **PASSED** ‚Äì telemetry shows branch/workspace preparation
  - [x] T16.5 Process Isolation ‚Äì **PASSED** ‚Äì PID namespace active; `ps` shows only sandbox processes (< 10 PIDs)
  - [x] T16.6 Network Isolation ‚Äì **PASSED** ‚Äì `CLONE_NEWNET` enabled by default; loopback only without `--allow-network`
  - [x] T16.7 Network Egress Enabled ‚Äì **PASSED** ‚Äì slirp4netns provides internet access with `--allow-network yes`
  - [x] T16.8 Secrets Protection ‚Äì **PASSED** ‚Äì sensitive directories (`~/.ssh`, `~/.gnupg`, `~/.aws`, etc.) hidden via tmpfs mounts
  - [x] T16.9 Writable Carveouts ‚Äì **PASSED** ‚Äì `--mount-rw` works correctly
  - [x] T16.10 Cleanup on Exit ‚Äì **PASSED** ‚Äì no stale mounts after normal exit
  - [x] T16.11 Crash Cleanup ‚Äì **PASSED** ‚Äì cleanup works after SIGKILL
  - [x] T16.12 Interrupt Cleanup ‚Äì **PASSED** ‚Äì cleanup works after SIGINT (61s test)
  - [ ] T16.13 Resource Limits ‚Äì pending (requires cgroup integration verification)
  - [ ] T16.14 Debugging Enabled ‚Äì pending (requires ptrace scenario)
  - [x] T16.15 Read-only Baseline ‚Äì **PASSED** ‚Äì /usr/bin write blocked
  - [x] T16.16 Provider Telemetry ‚Äì **PASSED** ‚Äì RUST_LOG=debug shows provider selection
  - [x] T16.17 Child Process Fork ‚Äì **PASSED** ‚Äì fork() works correctly in sandbox
  - [ ] T16.18 Child Process Exec ‚Äì pending
  - [ ] T16.19 Child Process System ‚Äì pending
  - [ ] T16.20 Child Process Nohup ‚Äì pending
  - [ ] T16.21 Child Process Setsid ‚Äì pending
  - [ ] T16.22 Child Process Double Fork ‚Äì pending
  - [x] T16.23 Child Process Shell Pipeline ‚Äì **PASSED** ‚Äì pipelines work correctly in sandbox
  - [x] T16.24 Child Process Subshell ‚Äì **PASSED** ‚Äì subshells work correctly in sandbox
  - [ ] T16.25 Base Layer Concurrent Create (Eager) ‚Äì pending (requires materialization mode integration)
  - [ ] T16.26 Base Layer Concurrent Modify (Eager) ‚Äì pending (requires materialization mode integration)
  - [ ] T16.27 Base Layer Lazy Visibility ‚Äì pending (requires materialization mode integration)
  - [ ] T16.28 Base Layer Delete Isolation (Eager) ‚Äì pending (requires materialization mode integration)
  - [ ] T16.29 Child Process Thread Spawn ‚Äì pending
  - [ ] T16.30 Child Process Cloexec ‚Äì pending

- **Implementation Notes** (Nov 2025):
  - **Double-fork pattern**: The sandbox now correctly uses a double-fork pattern for PID namespace isolation. After `unshare(CLONE_NEWPID)`, the process is NOT in the new PID namespace‚Äîonly its children are. The implementation forks twice: (1) first fork escapes tokio's multi-threaded runtime, (2) second fork enters the new PID namespace as PID 1.
  - **UID/GID mapping protocol**: After `unshare(CLONE_NEWUSER)`, the child cannot write its own `/proc/self/uid_map`. The parent process must write to `/proc/<child_pid>/uid_map` and `/proc/<child_pid>/gid_map`. The implementation uses pipe-based synchronization between parent and child.
  - **`/tmp` isolation**: A fresh tmpfs is mounted over `/tmp` inside the sandbox to prevent file leakage to the host. Exception: when working directory is under `/tmp` (like `/tmp/agentfs`), tmpfs mounting is skipped to preserve FUSE mounts‚ÄîAgentFS provides its own isolation in this case.
  - **Secrets protection**: Sensitive directories (`~/.ssh`, `~/.gnupg`, `~/.aws`, `~/.config/gcloud`, `~/.kube`, `~/.docker`) are hidden by mounting empty tmpfs filesystems over them. This prevents sandboxed processes from accessing credentials.
  - **Network isolation (M12)**: The sandbox now creates an isolated network namespace via `CLONE_NEWNET` by default. Inside the sandbox, only loopback (127.0.0.1) is available. When `--allow-network yes` is specified, `slirp4netns` is spawned from the parent process to provide user-mode TCP/IP stack for internet access.
  - **Test results**: 15 passed, 2 skipped, 0 failed. Skipped tests document features requiring additional prerequisites (overlay persistence) or handled by AgentFS (/tmp isolation when working under AgentFS mount).
  - **Key source files**: `crates/sandbox-core/src/process/mod.rs` (double-fork + uid_map + tmpfs + network), `crates/sandbox-core/src/namespaces/mod.rs` (CLONE_NEWNET), `crates/sandbox-core/src/tests.rs` (integration tests)

**F17. `ah agent start` Integration with AgentFS** (3‚Äì4d)

- **Prerequisites**: The AgentFS daemon must be running before executing these tests. Start it with `just start-ah-fs-snapshots-daemon` (requires sudo privileges). See [AgentFS Harness Runbook](../../../docs/AgentFS-Harness-Runbook.md) for daemon startup documentation.

- **Deliverables**:
  - Update the `ah agent start` CLI runtime selection logic so when `--fs-snapshots agentfs` (or the auto detector chooses AgentFS) the command discovers the already-running daemon, reuses its mount, and manages per-process branches through the control plane.
  - Reuse the `ah agent fs snapshot` plumbing to create/restore snapshots as part of workspace preparation, ensuring snapshot IDs flow into the task metadata that currently records provider selection.
  - Wire branch binding so every agent process is assigned to its own branch by calling the control plane before `ah agent record` launches the workload; track bindings for cleanup on exit.
  - Integrate with the local task manager and REST server workflows, ensuring AgentFS metadata is recorded in session payloads.

- **Success criteria (automated integration tests)**:
  - `ah agent start --agent echo --fs-snapshots agentfs --working-copy auto` completes end-to-end with recorded workspace metadata referencing the AgentFS provider.
  - Subsequent `ah agent fs snapshot list` shows the automatically created checkpoints.
  - Mount lifecycle automation guarantees no stale mounts remain after the agent terminates, even when the agent crashes or is interrupted.
  - Agent workspace is properly isolated; host filesystem remains untouched while agent edits persist in the AgentFS branch.

- **Automated Test Plan**:

  All tests assume the daemon is running via `just start-ah-fs-snapshots-daemon`. Tests should skip gracefully with actionable messages when the daemon is unavailable.
  - **T17.1 `test_agent_start_agentfs_basic_execution`** (`scripts/test-agentfs-agent-start.sh`):
    - **Properties verified**: Basic agent execution with AgentFS provider
    - **Steps**: Run `ah agent start --agent echo --fs-snapshots agentfs`, verify exit code 0
    - **Platforms**: Linux (FUSE), macOS (interpose)

  - **T17.2 `test_agent_start_agentfs_provider_recorded`**:
    - **Properties verified**: Provider metadata correctly recorded in SQLite state DB
    - **Steps**: Run `ah agent start --agent echo --fs-snapshots agentfs`, inspect SQLite state DB, verify recorded provider is `AgentFs` with mount metadata (mount path, branch ID)

  - **T17.3 `test_agent_start_agentfs_snapshot_creation`**:
    - **Properties verified**: Automatic snapshot creation during workspace preparation
    - **Steps**: Run `ah agent start`, then run `ah agent fs snapshot list`, verify at least one snapshot ID is returned

  - **T17.4 `test_agent_start_agentfs_workspace_isolation`**:
    - **Properties verified**: Agent workspace isolated from host; host filesystem untouched
    - **Steps**: (1) Capture host directory contents, (2) run agent that creates/modifies files, (3) verify host directory unchanged, (4) verify changes exist in AgentFS branch via control plane query

  - **T17.5 `test_agent_start_agentfs_branch_binding`**:
    - **Properties verified**: Agent process bound to dedicated branch; recorded in task metadata
    - **Steps**: Run agent start, parse recorder output for branch binding, verify branch ID in REC_SNAPSHOT entries

  - **T17.6 `test_agent_start_agentfs_cleanup_on_success`**:
    - **Properties verified**: Clean teardown when agent completes successfully
    - **Steps**: Run agent start with short-running agent, verify branch unbinding and no stale mounts

  - **T17.7 `test_agent_start_agentfs_crash_cleanup`**:
    - **Properties verified**: Cleanup when agent crashes (SIGKILL)
    - **Steps**: Start agent in background, send SIGKILL after 2s, verify branch unbinding and mount cleanup
    - **Spec reference**: Same cleanup requirements as F16.11

  - **T17.8 `test_agent_start_agentfs_interrupt_cleanup`**:
    - **Properties verified**: Cleanup when user interrupts (SIGINT)
    - **Steps**: Start agent in background, send SIGINT, verify graceful cleanup

  - **T17.9 `test_agent_start_agentfs_recorder_integration`**:
    - **Properties verified**: AgentFS branch IDs flow into `ah agent record` REC_SNAPSHOT entries
    - **Steps**: Run agent with recording enabled, parse recording output, verify REC_SNAPSHOT entries reference correct AgentFS branch labels

  - **T17.10 `test_agent_start_agentfs_sandbox_combined`** (Linux only):
    - **Properties verified**: Combined sandbox + AgentFS works (sandbox isolation + AgentFS overlay)
    - **Steps**: Run `ah agent start --agent echo --fs-snapshots agentfs --sandbox local`, verify both sandbox properties and AgentFS isolation

  - **T17.11 `test_agent_start_agentfs_telemetry`**:
    - **Properties verified**: Structured logs report provider selection, mount path, and branch ID
    - **Steps**: Run agent start with `RUST_LOG=debug`, parse logs for expected telemetry fields

  - **T17.12 `test_agent_start_agentfs_multiple_agents`**:
    - **Properties verified**: Multiple concurrent agents get separate branches; no cross-contamination
    - **Steps**: Start two agents in parallel, each creating unique files, verify each agent's files are isolated in their respective branches

- **Verification Results**:
  - [ ] T17.1 Basic Execution ‚Äì pending
  - [ ] T17.2 Provider Recorded ‚Äì pending
  - [ ] T17.3 Snapshot Creation ‚Äì pending
  - [ ] T17.4 Workspace Isolation ‚Äì pending
  - [ ] T17.5 Branch Binding ‚Äì pending
  - [ ] T17.6 Cleanup on Success ‚Äì pending
  - [ ] T17.7 Crash Cleanup ‚Äì pending
  - [ ] T17.8 Interrupt Cleanup ‚Äì pending
  - [ ] T17.9 Recorder Integration ‚Äì pending
  - [ ] T17.10 Sandbox Combined ‚Äì pending
  - [ ] T17.11 Telemetry ‚Äì pending
  - [ ] T17.12 Multiple Agents ‚Äì pending

### Test strategy & tooling

- **Unit Tests**: `cargo test` for adapter-specific logic, mocking FUSE library calls where possible
- **Integration Tests**: Real FUSE mounts using loopback devices and tmpfs backing stores
- **Compliance Tests**: pjdfstests suite with automated result parsing and regression detection
- **Performance Tests**: Custom benchmarking harness measuring throughput, latency, and resource usage
- **Stress Tests**: Concurrent operation testing with fault injection capabilities
- **Security Tests**: Input fuzzing and privilege escalation attempt simulation
- **CI Integration**: All tests run in isolated containers with proper cleanup and resource limits

#### End-to-end regression harness

- `scripts/run-fuse-regression.sh [mountpoint]` orchestrates the FUSE-specific workflow (manual mount, `sudo just test-fuse-basic`, `just test-fuse-basic-ops`, `just test-fuse-mount-cycle`, `just test-fuse-mount-concurrent`, and `just test-pjdfstest-full`). `just test-rust` is intentionally excluded to avoid unrelated blockers (e.g., missing git identity or tmux).
- The `mount-fuse.sh` helper enables `--allow-other` by default for multi-user scenarios. However, since the daemon now spawns the FUSE host as the requesting user (via privilege dropping), the control file `.agentfs/control` is owned by the user and does not require `--allow-other` for single-user CLI access.
- The script performs an initial cleanup (`umount-fuse` if the mountpoint is busy), captures per-step logs under `logs/fuse-e2e-<ts>/`, and enforces that the pjdfstest `summary.json` exactly matches the known-failure baseline (open/00, open/06, rename/00, rename/09, rename/10, chown/05, ftruncate/05, symlink/06, truncate/05, chmod/12, plus the chown/00 TODOs).
- Usage requires password-less `sudo` for the pjdfstest harness and the `test-fuse-basic` smoke test. Note that `just test-agentfs-cli-parity` no longer requires sudo since the FUSE mount is owned by the requesting user.

### Deliverables

- Complete FUSE adapter implementation with comprehensive test coverage
- Automated test suite with 40+ test scenarios covering all functionality
- Performance benchmarks and compliance validation results
- Packaging and distribution support for Linux ecosystems
- CI pipeline with full test automation and result reporting

### References

- [AgentFS Core Specification](AgentFS-Core.md)
- [AgentFS Control Messages](AgentFS-Control-Messages.md)
- [Compiling and Testing FUSE Filesystems](../../Research/Compiling-and-Testing-FUSE-File-Systems.md)
- libfuse documentation and examples
- pjdfstests compliance test suite
